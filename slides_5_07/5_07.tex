\documentclass{beamer}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{graphicx, caption, hyperref, url}
\usepackage[UTF8, noindent]{ctexcap}

\usetheme{Boadilla}

\title{0507汇报}
\author{朱睿涵 \and 李宸亦}
\institute{项目三}
\date{\today}

\begin{document}

\frame{\titlepage} % 标题页

\AtBeginSection{
    \begin{frame}
        \frametitle{目录}

        \tableofcontents[currentsection]
    \end{frame}
}

\section{华为PANGU-BOT}
% 在这里插入PANGU-BOT部分的slides
\begin{frame}
    \frametitle{标题}

    PANGU-BOT部分的slides

\end{frame}

\section{百度PLATO-XL}
\begin{frame}
    \frametitle{PLATO系列}

    PLATO系列：百度这两年针对NLP对话领域提出的一系列预训练的模型。

    \begin{itemize}
        \item PLATO
        \item PLATO-2
        \item PLATO-XL
    \end{itemize}

    从PLATO到PLATO-XL，使用的数据越来越多，模型大小越来越大，但是在PLATO-XL中模型的结构实际上更加简单了。
\end{frame}

\subsection{PLATO-XL模型结构}
\begin{frame}
    \frametitle{模型结构}

    \begin{figure}[tb]
        \centering
        \includegraphics[width=0.9\textwidth]{fig/plato-xl_arc.png}
    \end{figure}

    \begin{itemize}
        \item 抛弃了PLATO的隐变量和PLATO-2的课程学习的方法，直接训练
        \item 沿袭PLATO中使用的unified transformer
        \item 只保留了负对数似然（NLL）作为对话生成的预训练目标
        \item 训练时加入了多角色感知的预训练
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{为何采用unified transformer}

    传统用Transformer的对话生成：使用encoder-decoder结构。

    使用unified transformer的两方面好处：

    \begin{enumerate}
        \item 提升训练效率
        \begin{itemize}
            \item 传统：对话样本长短不一
            \item padding补齐带来大量的无效计算
            \item unified transformer：可以对输入样本进行有效的排序
        \end{itemize}
        \item 提高参数性价比
        \begin{itemize}
            \item 可以\textbf{同时}进行对话理解和回复生成的联合建模
            \item 灵活的注意力机制
            \item 对context进行了双向编码
            \item 对response进行了单向解码
        \end{itemize}
    \end{enumerate}
\end{frame}

\subsection{多角色感知的预训练}
\begin{frame}
    \frametitle{多角色感知的预训练}

    目的：

    \begin{itemize}
        \item 改善对话模型有时候自相矛盾的问题
        \item 提升多轮对话上的一致性
    \end{itemize}

    产生矛盾的原因：

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{fig/plato_example.png}
    \end{figure}

    对话模型所用的预训练语料：社交媒体对话

    \begin{itemize}
        \item 特点：通常有多个用户参与
        \item 训练时模型较难区分对话上文中不同角度的观点和信息
        \item 容易产生一些自相矛盾的回复
    \end{itemize}

\end{frame}

\subsection{实验结果}

\begin{frame}
    \frametitle{实验结果}

    评估方法：采用了两个模型针对开放域进行相互对话（self-chat）的形式，然后再通过人工来评估效果。

    \begin{itemize}
        \item PLATO-XL与Facebook Blender、微软DialoGPT、清华EVA模型、PLATO-2相比，取得了更优异的效果
        \item PLATO-XL也显著超越了目前主流的商用聊天机器人
        \item 除了开放域闲聊对话，模型也可以很好的支持知识型对话和任务型对话，在多种对话任务上效果全面领先
        \item 模型规模扩大对于效果提升也有显著作用，呈现较稳定的正相关关系
    \end{itemize}

\end{frame}

\section{Facebook Blender}

\begin{frame}

    \frametitle{Facebook Blender}

    这篇论文融合了Facebook Blender这个组近些年来在open-domain chatbot方向的诸多相关工作，读起来有些吃力。

    论文中提出了三个模型：

    \begin{itemize}
        \item 检索模型（Retriever）
        \item 生成模型（Generator）
        \item 检索 + 生成（Retrieve and Refine）
    \end{itemize}
\end{frame}

\subsection{三个模型}
\begin{frame}
    \frametitle{检索模型（Retriever）}

    从候选集中选取最合适的句子作为bot当前的答复。

    \begin{itemize}
        \item 训练时，候选集只有给定的一句response
        \item 推断时，候选集由训练集中的所有response组成
    \end{itemize}

    打分 / 排序模型使用他们在之前的论文中提出的Poly-encoder模型。

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{fig/Poly-encoder.png}
    \end{figure}

    实验表明：m越大效果越好，当然模型打分也越耗时。
\end{frame}

\begin{frame}
    \frametitle{生成模型（Generator）}

    模型结构：

    \begin{itemize}
        \item 标准的seq2seq结构，只是用了标准的Transformer层
        \item encoder层数少，decoder层数多的设计
    \end{itemize}

    Blender使用beam search，但是加入了一些限制方法：

    \begin{itemize}
        \item 限制生成response的最小长度：
            \begin{itemize}
                \item Minimum length
                \item Predictive length
            \end{itemize}
        \item 屏蔽重复的子序列
    \end{itemize}

    beam search的这些限制方法实际上都是锦上添花，如果模型本身的质量不高，上述的方法作用也不大。
\end{frame}

\begin{frame}
    \frametitle{生成模型（Generator）}

    训练方法：

    \begin{itemize}
        \item Seq2seq模型标准的训练方法MLE
        \item Unlikelihood Loss
    \end{itemize}

    Unlikelihood Loss（UL）是作者在之前的论文中提出的一种损失函数，在提高正确的token概率的同时，降低其他token的概率。

    \begin{block}{UL的关键}
        如何选取这些被打压的负token。

        \begin{itemize}
            \item 作者选的是那些容易组合成常见n-grams的tokens。
            \item 目的：期望降低生成无意义response的比例。
        \end{itemize}
    \end{block}

\end{frame}

\begin{frame}
    \frametitle{检索+生成（Retrieve and Refine）}

    Retrieve and Refine (RetNRef) 融合了检索和生成两种方法，是作者在18年的论文中提出的。

    \begin{block}{RetNRef}
        \begin{enumerate}
            \item 先利用检索模型检索出一个结果
            \item 把检索出的结果拼接到context后面，用一个特殊的分割符和context分隔
            \item 整体作为generator模型的输入
        \end{enumerate}
    \end{block}

    目的：期望生成模型能学习到在合适的时候从检索结果中copy词或词组。
\end{frame}

\begin{frame}
    \frametitle{检索+生成（Retrieve and Refine）}

    两种检索方法：

    \begin{description}
        \item[Dialogue Retrieval] 从训练数据中检索出得分最高的response作为结果
        \item[Knowledge Retrieval] 从外部的大知识库如Wiki中检索
    \end{description}

    \begin{itemize}
        \item 对于 Knowledge Retrieval，把检索出的结果直接追加到context后面，然后利用标准的 MLE 训练即可
        \item 对于 Dialogue Retrieval，直接利用MLE训练会有问题。训练出来的模型很容易直接忽略掉追加的检索部分
    \end{itemize}

    \begin{block}{$\alpha$ -blending}
        训练时以 $\alpha \%$ 的概率把检索结果替换为实际response。

        这样模型就会被吸引去关注检索部分了。
    \end{block}
\end{frame}

\subsection{数据集}
\begin{frame}
    \frametitle{数据集}

    数据集公认的标准：

    \begin{itemize}
        \item 对话要个性有趣
        \item 对话要包含知识
        \item 对话要富有同理心
    \end{itemize}

    作者在他之前的论文中发现：\textbf{在具有某些特性的数据上训练出的模型也会拥有这些特性}。

    \begin{columns}
        \begin{column}{.5\textwidth}
            训练使用的数据集：
            \begin{itemize}
                \item http://pushshift.io Reddit
                \item ConvAI2
                \item Empathetic Dialogues (ED)
                \item Wizard of Wikipedia (WoW)
                \item Blended Skill Talk (BST)
            \end{itemize}
        \end{column}
        \begin{column}{.5\textwidth}
            模型训练流程：
            \begin{enumerate}
                \item 在http://pushshift.io Reddit上进行预训练
                \item 在ConvAI2、ED、WoW上多任务精调
                \item 在BST上精调
            \end{enumerate}
        \end{column}
    \end{columns}

    在优质数据上训练模型，也能降低模型产生不好的response的概率。
\end{frame}

\subsection{实验结果}
\begin{frame}
    \frametitle{评估方法}

    自动评估：

    \begin{itemize}
        \item 生成模型采用Perplexity(PPL)
        \item 检索打分模型采用Hits@1/K
    \end{itemize}

    人工评估：

    \begin{itemize}
        \item ACUTE-Eval：
        \begin{enumerate}
            \item 每次给两个对话session
            \item 让人来评判哪个speaker聊的更好
            \item ACUTE-Eval可以给出两个speaker各自的胜率
        \end{enumerate}
        \item Self-Chat ACUTE-Eval：和ACUTE-Eval的做法类似，只是评估时用的是自己跟自己聊的session。
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{评估结果}

    PPL：

    \begin{itemize}
        \item 模型越大PPL越低
        \item RetNRef 相比于同等规模的生成模型，PPL会略有提升
    \end{itemize}

    Self-Chat ACUTE-Eval：

    \begin{itemize}
        \item 相同尺寸，Generator和RetNRef模型都未使用最小长度约束时：Retrieval比RetNRef略好，二者都远远好于Generative。
        \item Beam Search中加入限制方法：
        \begin{itemize}
            \item 限制最小生成长度效果显著，最小长度限制设为20效果最好
            \item 子序列屏蔽有点用，但不显著
        \end{itemize}
        \item 精调后的模型比只进行预训练的模型效果好很多
        \item Unlikelihood Loss 比 MLE 效果好一点点，但不显著
    \end{itemize}

\end{frame}

\begin{frame}
    \frametitle{评估结果}

    ACUTE-Eval：

    \begin{itemize}
        \item 相同尺寸Generator 和 RetNRef 模型使用的 beam search 都加入了最小长度20的限制：Generator 和 RetNRef 显著优于 Retrieval，RetNRef 略优于 Generative，但不显著。
        \item Blender 显著优于 Meena，胜率高达70\%
        \item Blender最好的模型和人 PK 的胜率已经到了 49\%，与人类的差距仅有1\%
    \end{itemize}

\end{frame}

\subsection{模型的问题}
\begin{frame}
    \frametitle{模型存在的问题}

    \begin{itemize}
        \item 倾向于使用高频词
        \item 倾向于生成重复信息
        \item 模型生成的答复可能前后冲突
        \item 其他问题：
        \begin{itemize}
            \item 无法针对某个话题做深度对话，不会倾向于使用更多知识进行深聊
            \item 模型无法深度理解，无法通过对话真正教会模型理解某个概念
            \item 当前的评测针对的是14轮长度的对话，分析更长的对话肯定会发现其他问题
        \end{itemize}
    \end{itemize}

\end{frame}

\subsection{Blender总结}
\begin{frame}
    \frametitle{Blender总结}

    \begin{itemize}
        \item 大模型、大数据集对实验结果提升极其显著
        \item 训练数据的特性决定模型特性
        \item 评估方法使用 ACUTE-Eval、 Self-Chat ACUTE-Eval
        \item 对decoding过程加入控制，比如控制生成句子长度，效果会更佳
        \item Blender在轮次少的情况下已经接近人类的水平，但目前还有很多问题待解决
    \end{itemize}

\end{frame}
\end{document}